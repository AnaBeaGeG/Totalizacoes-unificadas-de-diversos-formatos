{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias\n",
    "import os #uma biblioteca que nos permite interagir com o sistema operacional, como navegar pelos diretórios\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from simpledbf import Dbf5 #Converte arquivo DBF para arquivo CSV\n",
    "from dbfread import DBF\n",
    "from openpyxl import load_workbook\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao para percorrer todos arquivos em formato dbf nas pastas da rede do laboratorio\n",
    "def encontrar_dbf(tabela, empresa, ano, cod_emp):\n",
    "    ano = int(ano)\n",
    "    arquivos_dbf = []\n",
    "   \n",
    "\n",
    "    if ano not in np.arange(2004,2009): #Os anos entre 2009 e 2017 foram armazenados em caminhos de estruturação distinta e não serão usados neste relatorio\n",
    "        ano = str(ano)\n",
    "        caminho_inicial = fr'\\\\PROJETOS2\\CDs_{ano}\\{empresa}\\{cod_emp}'\n",
    "        for root, dirs, files in os.walk(caminho_inicial): #Permite fazer uma busca recursiva no diretório e seus subdiretórios\n",
    "            #A função os.walk retorna um gerador que produz tuplas contendo três elementos: o diretório atual, uma lista dos subdiretórios presentes nesse diretório e uma lista dos arquivos presentes nesse diretório.\n",
    "            path_components = root.split(os.sep)\n",
    "        \n",
    "            #if cod_emp in path_components and empresa in path_components or cod_emp.strip('0') in path_components:\n",
    "            if any( cod_emp[1:] in item or cod_emp in item for item in path_components) and any( empresa.lower() in item.lower() for item in path_components) and all('excluir' not in item.lower() for item in path_components) and all('lixo' not in item.lower() for item in path_components) and all( 'old' not in item.lower() for item in path_components):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(\".dbf\") and file.lower().startswith(f\"{tabela.lower()}\"): #Selecioanos os tipos de arquivos desejados\n",
    "                        arquivos_dbf.append(os.path.join(root, file))\n",
    "\n",
    "    if len(arquivos_dbf) == 0:    \n",
    "       return [0] \n",
    "   \n",
    "    return arquivos_dbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao para realizar as contagens basicas dos arquivos em formato dbf encontrados na função anterior\n",
    "def arq_dbf (tabelas, cod_emps, empresa, anos):\n",
    "    \n",
    "    linhas_resultados = [] # Armazenar resultados intermediários para concatenação final\n",
    "    logs= []\n",
    "    \n",
    "    for tabela in tabelas:\n",
    "\n",
    "        for ano in anos:\n",
    "\n",
    "            for cod_emp in cod_emps:\n",
    "                #Para cada tipo de tabela, ano e codigo da empresa buscamos os caminhos correspondentes \n",
    "                caminhos = encontrar_dbf(tabela, empresa, ano, cod_emp)\n",
    "                \n",
    "                #Caso exista mais de um envio para at ou sa, por exemplo\n",
    "                for caminho in caminhos:\n",
    "\n",
    "                    tipo = tabela[:2]\n",
    "                    ramo = tabela[3:6]\n",
    "\n",
    "                     # Se o arquivo não foi encontrado, passa para a próxima iteração\n",
    "                    if caminho == 0:\n",
    "                        #print(f\"Diretório não encontrado para a empresa {empresa} de cod_emp {cod_emp} no ano {ano}.\")\n",
    "                        linhas_log = pd.DataFrame({'ANO': [ano], 'EMPRESA': [empresa], 'COD_EMP': [cod_emp], 'TIPO': [tipo], 'RAMO': [ramo],'QTDE_LINHAS_TOTAL_DBF': 0})\n",
    "                        logs.append(linhas_log)\n",
    "\n",
    "                    else:\n",
    "                        #Se o arquivo foi encontrado, primeiro tenta converter o dbf para csv, caso não dê certo mostra uma mensagem\n",
    "                        try:\n",
    "                            table = DBF(caminho, load=False) \n",
    "                            qtde_linhas_total = len(table)\n",
    "                            linhas = pd.DataFrame({'ANO': [ano], 'EMPRESA': [empresa], 'COD_EMP': [cod_emp], 'TIPO': [tipo], 'RAMO': [ramo],'QTDE_LINHAS_TOTAL_DBF':[qtde_linhas_total] })\n",
    "                            linhas_resultados.append(linhas) \n",
    "\n",
    "                        except Exception as erro:\n",
    "                            print(f\"Erro ao processar o arquivo DBF para a empresa {empresa}, cod_emp {cod_emp}, ano {ano}: {erro}\")\n",
    "\n",
    "    if len(logs) == 0: #Caso todos os arquivos tenham sido encontrados mostrar apenas um dataFrame vazio\n",
    "        resultado_log = pd.DataFrame()\n",
    "    else:\n",
    "        resultado_log = pd.concat(logs, ignore_index=True)    \n",
    "        \n",
    "    if len(linhas_resultados) == 0: #Caso nenhum arquivo tenha sido encontrado\n",
    "        resultados_dbf = resultado_log\n",
    "    else:\n",
    "        resultados_dbf = pd.concat(linhas_resultados, ignore_index=True) #Vou guardar todos os DataFrames em uma lista e concatenar tudo ao final.\n",
    "        resultados_dbf = resultados_dbf.groupby(['COD_EMP','ANO','EMPRESA','RAMO','TIPO'])['QTDE_LINHAS_TOTAL_DBF'].sum().reset_index()  \n",
    "    \n",
    "    return resultados_dbf, resultado_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem basica dos arquivos que estão em formato parquet\n",
    "def arq_parquet (tabelas, empresa, anos, cod_emps):\n",
    "    \n",
    "    logs = []\n",
    "    resultados_parquet = []\n",
    "\n",
    "    for tabela in tabelas:\n",
    "        \n",
    "        for ano in anos:\n",
    "\n",
    "            base = fr'\\\\PROJETOS\\{ano}\\{empresa.upper()}'\n",
    "            tipo = tabela[:2]\n",
    "            ramo = tabela[3:6]\n",
    "            parquets_diretorio = os.path.join(base,tabela)\n",
    "\n",
    "            #Procura os parquets\n",
    "\n",
    "            if not os.path.exists(parquets_diretorio) and len(tabelas) == 1: #Caso em que só seja selecionado o ano em que não há parquets\n",
    "                print(f\"Não há totalizações da {tabela} para mostar para a {empresa} no ano de {ano}\")\n",
    "\n",
    "            if not os.path.exists(parquets_diretorio): \n",
    "                #print(f\"Diretorio {parquets_diretorio} não encontrado.\")\n",
    "                linhas_log = pd.DataFrame({'ANO': [ano], 'EMPRESA': [empresa], 'COD_EMP': [cod_emps], 'TIPO': [tipo], 'RAMO': [ramo],'QTDE_LINHAS_TOTAL_PARQUET': 0})\n",
    "                linhas_log = linhas_log.explode('COD_EMP', ignore_index=True) # Expande a coluna COD_EMP para que cada valor tenha uma linha separada\n",
    "                logs.append(linhas_log)\n",
    "                continue\n",
    "            \n",
    "            parquets = os.listdir(parquets_diretorio) #Lista todos os arquivos em parquet dentro da pasta de uma empresa dentro daquele ano para a tabela desejada\n",
    "\n",
    "            for p in parquets:\n",
    "                parquets_path = os.path.join(parquets_diretorio,p)\n",
    "                aux = pd.read_parquet(f'{base}\\\\{tabela}\\\\{p}')\n",
    "\n",
    "                #filtra o DataFrame para o cod_emp selecionado\n",
    "                cod_emps = aux['COD_EMP'].unique()\n",
    "                for cod_emp in cod_emps:\n",
    "                    aux_cod_emp = aux[aux['COD_EMP']==cod_emp]\n",
    "            \n",
    "                    qtde_linhas_total = len(aux_cod_emp)\n",
    "\n",
    "                    #Junta os resultados_parquet de todas as iterações\n",
    "                    linhas =pd.DataFrame({'ANO': [ano], 'EMPRESA': [empresa], 'COD_EMP': [cod_emp], 'TIPO': [tipo], 'RAMO': [ramo],'QTDE_LINHAS_TOTAL_PARQUET':[qtde_linhas_total]})\n",
    "                    resultados_parquet.append(linhas)\n",
    "    \n",
    "    if len(logs) == 0: #Caso todos os arquivos tenham sido encontrados\n",
    "        resultado_log = pd.DataFrame()\n",
    "    else:\n",
    "        resultado_log = pd.concat(logs, ignore_index=True)         \n",
    "    \n",
    "    if len(resultados_parquet) == 0: #Caso nenhum arquivo tenha sido encontrado\n",
    "        resultados_parquet = resultado_log\n",
    "    else:\n",
    "        resultados_parquet = pd.concat(resultados_parquet, ignore_index=True) #Vou guardar todos os DataFrames em uma lista e concatenar tudo ao final.\n",
    "        \n",
    "           \n",
    "    return resultados_parquet , resultado_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualização geral das contagens \n",
    "def totaliza_uni (tabela, empresa, anos, cod_emps):\n",
    "    #Talvez o for tabelas e for anos e for empresas devesse ser aqui \n",
    "\n",
    "    print(f\"Executando totaliza com empresa={empresa}, tabela={tabela}, cod_emp={cod_emps} \\n\")\n",
    "\n",
    "    juncoes = ['ANO','EMPRESA','COD_EMP','TIPO','RAMO']\n",
    "    t1 = arq_dbf (tabela, cod_emps, empresa, anos)\n",
    "    t2 = arq_parquet (tabela, empresa, anos, cod_emps)\n",
    "    left = t1[0]\n",
    "    right = t2[0]\n",
    "    #Para evitar de armazenar tabela com linhas vazias, que é quando não tem registros para mostrar do segmento escolhido no argumento tabela\n",
    "    if t1[0].equals(t1[1]) and t2[0].equals(t2[1]): \n",
    "        ramo = tabela[0][3:6] #Quando houver a necessidade de rodar mais de uma tabela ao mesmo tempo haverá necessidade de mudança aqui\n",
    "        return f'A {empresa} não apresenta o segmento {ramo}'\n",
    "    \n",
    "    else:\n",
    "        #juntando as totalizações de cada arquivo parquet\n",
    "        right = right.groupby(['ANO','COD_EMP', 'EMPRESA','TIPO','RAMO'])[['QTDE_LINHAS_TOTAL_PARQUET']].sum().reset_index()\n",
    "    \n",
    "        #Fazendo um join com os DataFrames\n",
    "        resultado = pd.merge(left, right, on= juncoes, how='left')\n",
    "    \n",
    "        return resultado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserir os dados para cada empresa\n",
    "tabela = ['ATIVOS']\n",
    "anos = np.arange(2017,2024)\n",
    "\n",
    "guia = {'XXX':['00000'],'YYY':['11111']}\n",
    "\n",
    "\n",
    "empresas = guia.keys()\n",
    "\n",
    "planilha = fr\"cole o path desejado para armazenar o resultado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualização em uma tabela externa para verificação da consistencia entre as transformações de formato dos arquivos \n",
    "import winsound\n",
    "\n",
    "for empresa in empresas:\n",
    "    print(empresa)\n",
    "    cod_emps = guia[empresa]\n",
    "    #resultados_dbf = arq_dbf(tabela, cod_emps,empresa, anos)[1]\n",
    "    #resultados_parquet = arq_parquet(tabela, empresa, anos,cod_emps)[1]\n",
    "\n",
    "    #Criando uma planilha para armazenar todas as totalizações básicas e inserir a informação de percentual de dados faltantes\n",
    "    df_novo = totaliza_uni (tabela, empresa, anos, cod_emps)\n",
    "    if type(df_novo) == str:\n",
    "        continue\n",
    "     \n",
    "    df_novo.fillna(0) #Tratando os valores nulos \n",
    "    df_novo['percentual']= df_novo['QTDE_LINHAS_TOTAL_PARQUET'] / df_novo['QTDE_LINHAS_TOTAL_DBF']\n",
    "    #Reorganizando as colunas do df para corresponder com as colunas da planilha\n",
    "    df_novo = df_novo[['ANO','EMPRESA','COD_EMP','TIPO','RAMO','QTDE_LINHAS_TOTAL_DBF','QTDE_LINHAS_TOTAL_PARQUET','percentual']]\n",
    "\n",
    "    #Abrindo o arquivo para realizar modificações\n",
    "    with pd.ExcelWriter(planilha, mode='a', engine='openpyxl',if_sheet_exists='overlay') as writer: #Só isso não carrega as planilhas existentes, modo = a significa anexar\n",
    "        \n",
    "        #Caso vc rode esse codigo e depois apague o conteudo das celulas no arquivo, na hora da contagem elas são consideradas como preenchidas, por isso é necessario excluir a linha \n",
    "        df_novo.to_excel(writer, sheet_name='Página1', index=False, \n",
    "                                startrow=writer.sheets['Página1'].max_row, startcol = 0, header=False)\n",
    "\n",
    "# Emitir som após a execução\n",
    "winsound.Beep(1000, 500)  # Frequência 1000 Hz, duração de 500 ms\n",
    "\n",
    "#Referências de estudo:\n",
    "#https://www.datacamp.com/tutorial/python-excel-tutorial#rdl\n",
    "#https://xlsxwriter.readthedocs.io/working_with_pandas.html\n",
    "#https://www.tutorialspoint.com/how-to-get-the-maximum-number-of-occupied-rows-and-columns-in-a-worksheet-in-selenium-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRA\n",
    "\n",
    "#Poderia adicionar tambem a contagem basica dos arquivos que estão em formato csv. Que foi uma conversão intermediária dos arquivos entre dbf e csv\n",
    "def arq_csv(tabela, empresa, anos, cod_emp):\n",
    "    \n",
    "    tipo = tabela[:2]\n",
    "    ramo = tabela[3:6]\n",
    "    resultado = []\n",
    "    resultado_c_erro = []\n",
    "    for ano in anos:\n",
    "        \n",
    "        caminho_inicial = fr'\\\\PROJETOS\\CDs_{ano}\\{empresa}\\{cod_emp}'\n",
    "    \n",
    "\n",
    "        for root, dirs, files in os.walk(caminho_inicial): #Permite fazer uma busca recursiva no diretório e seus subdiretórios\n",
    "            #A função os.walk retorna um gerador que produz tuplas contendo três elementos: o diretório atual, uma lista dos subdiretórios presentes nesse diretório e uma lista dos arquivos presentes nesse diretório.\n",
    "            print(f'Rodando para a {empresa} no ano de {ano} procurando arquivos {tabela}.csv')\n",
    "            print(f\"Explorando diretório: {root} \\n\")\n",
    "\n",
    "            for file in files:\n",
    "    \n",
    "                if  file.lower() == f\"{tabela.lower()}.zip\":\n",
    "                    zip_path = os.path.join(root,file)\n",
    "\n",
    "                    # Abrir o arquivo ZIP\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                        arquivo_zip = zip_ref.namelist()\n",
    "\n",
    "                        try:\n",
    "                            with zip_ref.open(arquivo_zip[0]) as arquivo_csv: #Sempre só vai ter um arquivo no zip\n",
    "                                # Lê o CSV diretamente no pandas\n",
    "                                df = pd.read_csv(arquivo_csv)\n",
    "                                qtde_linhas_total = df.shape[0]\n",
    "                                linhas =pd.DataFrame({'ANO': [ano], 'EMPRESA': [empresa], 'COD_EMP': [cod_emp], 'TIPO': [tipo], 'RAMO': [ramo],'QTDE_LINHAS_TOTAL_CSV':[qtde_linhas_total]})\n",
    "\n",
    "                                if len(files) > 1: #Condicional para realizar agrupamento só para os casos em que haja mais de um arquivo para um conjunto específico de tabela,empresa,ano e cod_emp\n",
    "                                    print(f'Feito agrupamento para a {empresa} no ano {ano}')\n",
    "                                    linhas = linhas.groupby(['ANO','EMPRESA','COD_EMP','TIPO','RAMO'])['QTDE_LINHAS_TOTAL_CSV'].sum().reset_index()  \n",
    "\n",
    "                                else:\n",
    "                                    linhas\n",
    "\n",
    "                                resultado.append(linhas)\n",
    "\n",
    "                        except Exception as e:\n",
    "                        # Caso dê erro, adiciona à lista de arquivos com erro\n",
    "                            print(f\"Erro ao ler o arquivo {zip_path}: {e}\")\n",
    "                            resultado_c_erro.append(zip_path)\n",
    "            \n",
    "\n",
    "    if len(resultado) == 0:    \n",
    "        return f'Não há {tabela}.csv para {empresa} no {ano}' \n",
    "    \n",
    "    resultado = pd.concat(resultado,ignore_index=True)      \n",
    "    resultado = resultado.groupby(['ANO','EMPRESA','COD_EMP','TIPO','RAMO'])['QTDE_LINHAS_TOTAL_CSV'].sum().reset_index()  \n",
    "\n",
    "    return resultado , resultado_c_erro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
